from utils.llm_client import get_llm_client, get_model_setting
from utils.mcp_servers_config import get_mcp_servers_config
import chainlit as cl
from chainlit.input_widget import Select, Switch
from typing import Dict, Any, List, Optional, Literal
from mcp.types import CallToolResult, TextContent
import os
import json
import base64
import io
from markitdown import MarkItDown
import datetime
import asyncio
import httpx
from utils.mcp_manager_legacy import MCPConnectionManager
from chainlit_app.overseer import render_overseer_for_user, run_overseer
from foobar_provider import FooBarProvider
from inject_custom_auth import add_custom_oauth_provider

add_custom_oauth_provider("foobar", FooBarProvider())

@cl.oauth_callback
def oauth_callback(
  provider_id: str,
  token: str,
  raw_user_data: Dict[str, str],
  default_user: cl.User,
) -> Optional[cl.User]:
  return default_user  

async def encode_image(image_path):
    """éåŒæ­¥ç·¨ç¢¼åœ–ç‰‡ç‚º base64ï¼Œä½¿ç”¨ aiofiles é€²è¡ŒéåŒæ­¥æª”æ¡ˆè®€å–"""
    import aiofiles
    async with aiofiles.open(image_path, "rb") as image_file:
        image_data = await image_file.read()
        result = await asyncio.to_thread(base64.b64encode, image_data)
    return result.decode('utf-8')

async def get_files_state(folder_path):
    """å–å¾—è³‡æ–™å¤¾ä¸­æ‰€æœ‰æª”æ¡ˆçš„ç‹€æ…‹ï¼ˆæª”æ¡ˆåç¨±å’Œä¿®æ”¹æ™‚é–“ï¼‰
    
    Args:
        folder_path: è³‡æ–™å¤¾è·¯å¾‘
        
    Returns:
        dict: {filename: mtime} æ ¼å¼çš„å­—å…¸ï¼Œè¨˜éŒ„æ¯å€‹æª”æ¡ˆçš„ä¿®æ”¹æ™‚é–“
    """
    files_state = {}
    if folder_path and await asyncio.to_thread(os.path.exists, folder_path):
        file_list = await asyncio.to_thread(os.listdir, folder_path)
        for filename in file_list:
            file_path = os.path.join(folder_path, filename)
            if await asyncio.to_thread(os.path.isfile, file_path):
                mtime = await asyncio.to_thread(os.path.getmtime, file_path)
                files_state[filename] = mtime
    return files_state

async def check_and_process_new_files(existing_files, append_to_history=False):
    """æª¢æŸ¥ä¸¦è™•ç†å·¥å…·ç”Ÿæˆçš„æ–°æª”æ¡ˆï¼ˆåŒ…æ‹¬åœ–ç‰‡å’Œå…¶ä»–æª”æ¡ˆï¼‰
    
    Args:
        existing_files: dictï¼Œæ ¼å¼ç‚º {filename: mtime}ï¼Œè¨˜éŒ„åŸ·è¡Œå·¥å…·å‰çš„æª”æ¡ˆç‹€æ…‹
        append_to_history: boolï¼Œæ˜¯å¦å°‡åœ–ç‰‡åŠ å…¥å°è©±æ­·å²
    """
    file_folder = cl.user_session.get('file_folder')
    if not file_folder or not await asyncio.to_thread(os.path.exists, file_folder):
        return
    
    # æ”¯æ´çš„åœ–ç‰‡æ ¼å¼
    image_extensions = {'.png', '.jpg', '.jpeg', '.gif', '.bmp', '.webp', '.svg'}
    
    # å–å¾—ç•¶å‰æª”æ¡ˆç‹€æ…‹
    current_files = await get_files_state(file_folder)
    
    # æ‰¾å‡ºæ–°æª”æ¡ˆæˆ–è¢«ä¿®æ”¹çš„æª”æ¡ˆ
    new_or_modified_files = []
    for filename, current_mtime in current_files.items():
        if filename not in existing_files or existing_files[filename] != current_mtime:
            new_or_modified_files.append(filename)
    
    if not new_or_modified_files:
        return
    
    # åˆ†é¡æ–°æª”æ¡ˆæˆ–è¢«ä¿®æ”¹çš„æª”æ¡ˆ
    new_images = []
    other_files = []
    
    for f in new_or_modified_files:
        filename, extension = await asyncio.to_thread(os.path.splitext, f.lower())
        if extension in image_extensions:
            new_images.append(f)
        else:
            other_files.append(f)
    
    # æº–å‚™æ‰€æœ‰å…ƒç´ 
    all_elements = []
    image_content = []
    
    # è™•ç†åœ–ç‰‡æª”æ¡ˆ
    for image_file in new_images:
        image_path = os.path.join(file_folder, image_file)
        filename, extension = await asyncio.to_thread(os.path.splitext, image_file.lower())

        # å…¶ä»–åœ–ç‰‡æ ¼å¼ä½¿ç”¨åŸæœ‰çš„ path æ–¹å¼
        image_element = cl.Image(
            name=image_file,
            path=image_path,
            display="inline"
        )
        all_elements.append(image_element)
        
        # å°‡åœ–ç‰‡åŠ å…¥åˆ°å…§å®¹ä¸­
        image_content.append({
            "type": "image_url",
            "image_url": {
                "url": f"data:image/jpeg;base64,{await encode_image(image_path)}",
                "detail": "high"
            }
        })
    
    # è™•ç†å…¶ä»–æª”æ¡ˆ
    for file_name in other_files:
        file_path = os.path.join(file_folder, file_name)
        
        # å‰µå»ºæª”æ¡ˆå…ƒç´ ä¾›ä¸‹è¼‰
        file_element = cl.File(
            name=file_name,
            path=file_path,
            display="inline",
        )
        all_elements.append(file_element)

    # ä¸€æ¬¡ç™¼é€æ‰€æœ‰å…ƒç´ åˆ° UI
    if all_elements:
        content_parts = []
        if new_images:
            content_parts.append(f"ğŸ–¼ï¸ ç”¢ç”Ÿäº† {len(new_images)} å€‹åœ–ç‰‡æª”æ¡ˆ")
        if other_files:
            content_parts.append(f"ğŸ“ ç”¢ç”Ÿäº† {len(other_files)} å€‹æª”æ¡ˆå¯ä¾›ä¸‹è¼‰")
        
        content = "ã€".join(content_parts) if content_parts else ""
        
        await cl.Message(
            content=content,
            elements=all_elements
        ).send()
        
        # å°‡åœ–ç‰‡åŠ å…¥åˆ° message_history ä¸­ï¼ˆåªæœ‰åœ–ç‰‡éœ€è¦åŠ å…¥å°è©±æ­·å²ï¼‰
        if append_to_history and image_content:
            message_history = cl.user_session.get("message_history", [])
            image_message = {
                "role": "assistant",
                "content": image_content
            }
            message_history.append(image_message)
            # æ›´æ–° session ä¸­çš„ message_history
            cl.user_session.set("message_history", message_history)
    
@cl.step(name="æª”æ¡ˆæ–‡æœ¬æå–")
async def convert_to_markdown(file_path, model="gpt-4o-mini", use_vision_model=False):
    # æ ¹æ“šè¨­å®šæ±ºå®šæ˜¯å¦ä½¿ç”¨è¦–è¦ºèªè¨€æ¨¡å‹
    if use_vision_model:
        client = get_llm_client(mode="sync")
        md = MarkItDown(enable_plugins=True, llm_client=client, llm_model=model)
    else:
        md = MarkItDown(enable_plugins=True)
    
    # å°‡åŒæ­¥çš„ md.convert åŒ…è£æˆéåŒæ­¥å‘¼å«
    result = await asyncio.to_thread(md.convert, file_path)
    
    return result.text_content


@cl.on_chat_start
async def start():
    userinfo = cl.user_session.get('user')
    await cl.Message(content=f'### ä½ å¥½ {userinfo.identifier}ï¼Œæ­¡è¿å›ä¾†!ã€€à´¦àµà´¦à´¿(Ëµ â€¢Ì€ á´— - Ëµ ) âœ§').send()
    file_folder = await asyncio.to_thread(os.path.join, os.getcwd(), '.files', cl.user_session.get('id'))
    if not await asyncio.to_thread(os.path.exists, file_folder):
        await asyncio.to_thread(os.mkdir, file_folder)
    cl.user_session.set('file_folder', file_folder)
    cl.user_session.set(
        "message_history",
        [
            {
                "role": "system",
                "content": "You are a helpful å°ç£ç¹é«”ä¸­æ–‡ AI assistant. You can access tools. å¦‚æœæœ‰å¯ä»¥èª¿ç”¨promptå‡ºä¾†æŸ¥çœ‹æ–‡å­—æµç¨‹çš„å·¥å…·ï¼Œæ ¹æ“šä»»å‹™æ€§è³ªå…ˆè¡Œèª¿ç”¨ç¢ºèªä½¿ç”¨è€…è¨­å®šçš„æµç¨‹prompt",
            },
            {
                "role": "assistant",
                "content": f"ç¾åœ¨æ™‚é–“æ˜¯ {datetime.datetime.now()}ï¼Œä»¥ä¸‹ç‚ºä½¿ç”¨è€…ç™»å…¥è³‡è¨Š:{userinfo.to_json()}",
            }
        ],
    )
    # å»ºç«‹è¨­å®šé¸é …
    settings_widgets = []
    
    # æ–°å¢è¦–è¦ºèªè¨€æ¨¡å‹è¨­å®šé¸é …
    settings_widgets.append(
        Switch(
            id="use_vision_model",
            label="ä½¿ç”¨è¦–è¦ºèªè¨€æ¨¡å‹æè¿°æª”æ¡ˆä¸­çš„åœ–ç‰‡",
            initial=False,
            description='å•Ÿç”¨å¾Œï¼Œåœ¨è§£ææª”æ¡ˆå¦‚PDFã€PPTæ™‚ MarkItDown å°‡ä½¿ç”¨ GPT-4o-mini ç­‰è¦–è¦ºèªè¨€æ¨¡å‹ä¾†åˆ†æå’Œæè¿°æª”æ¡ˆä¸­çš„åœ–ç‰‡å…§å®¹ï¼Œæä¾›æ›´è©³ç´°çš„åœ–ç‰‡èªªæ˜ã€‚ä½†æœƒå¢åŠ é¡å¤–çš„è™•ç†æ™‚é–“èˆ‡ Token è²»ç”¨'
        )
    )
    # playwright è¨­å®š
    mcp_config = get_mcp_servers_config(file_folder)
    if "playwright" in mcp_config:
        mcp_config['playwright']['args'] += [f"--output-dir={file_folder}"]
    
    if 'filesystem' in mcp_config:
        mcp_config.get('filesystem')['args'].append(file_folder)

    if 'buildin' in mcp_config:
        if not mcp_config['buildin'].get('env'):
            mcp_config['buildin']['env'] = {}
        mcp_config['buildin']['env']['ROOT_FOLDER'] = file_folder

    # æ–°å¢ MCP ä¼ºæœå™¨è¨­å®šé¸é …
    for server_name, config in mcp_config.items():
        settings_widgets.append(
            Switch(
                id=f"mcp_{server_name}",
                label=f"MCP - {config['name']}",
                initial=config['enabled']
            )
        )
    
    settings = await cl.ChatSettings(settings_widgets).send()
    cl.user_session.set('chat_setting', settings_widgets)
    cl.user_session.set('current_settings', settings)

    # ç¢ºä¿æ¯å€‹æœƒè©±éƒ½æœ‰å”¯ä¸€çš„ MCP ç®¡ç†å™¨å¯¦ä¾‹
    session_id = cl.user_session.get('id')
    mcp_manager = MCPConnectionManager(
        id=session_id, 
        config=mcp_config, 
        on_connect=on_mcp_connect, 
        on_disconnect=on_disconnect,
        on_elicit=on_mcp_elicit,
        on_progress=on_mcp_progress
    )
    cl.user_session.set('mcp_manager', mcp_manager)
    
    # æ ¹æ“šåˆå§‹è¨­å®šé€£ç·šå·²å•Ÿç”¨çš„ä¼ºæœå™¨
    for server_name, config in mcp_config.items():
        setting_key = f"mcp_{server_name}"
        if settings.get(setting_key, config.get('enabled', False)):
            # await cl.Message(content=f"â³ æ­£åœ¨é€£ç·šåˆ° MCP ä¼ºæœå™¨: {server_name}").send()
            await mcp_manager.add_connection(server_name, config)

async def on_mcp_connect(name, tools=[]):
    mcp_config = get_mcp_servers_config(cl.user_session.get('file_folder'))
    await cl.Message(content=f'ğŸ”— å·²é€£ç·š `{mcp_config[name]['name']}`').send()
    
    # åœ¨è¨­å®šä»‹é¢ä¸­æ›´æ–°è©²MCPçš„é¸é …æè¿°
    chat_setting = cl.user_session.get('chat_setting', [])
    for element in chat_setting:
        if element.id == f"mcp_{name}":
            element.description = ', '.join([f"{t['name']}" for t in tools])
            break
        
    cl.user_session.set('chat_setting', chat_setting)
    settings = await cl.ChatSettings(chat_setting).send()

async def on_disconnect(name):
    await cl.Message(content=f"ğŸ”Œ å·²æ–·ç·š MCP ä¼ºæœå™¨: {name}").send()

@cl.on_chat_end
async def end():
    mcp_manager = cl.user_session.get('mcp_manager')
    if mcp_manager:
        await mcp_manager.shutdown()
        
@cl.on_settings_update
async def on_settings_update(settings):
    """è™•ç†è¨­å®šè®Šæ›´ï¼Œé€£ç·šæˆ–æ–·ç·š MCP ä¼ºæœå™¨"""
    print("è¨­å®šå·²æ›´æ–°:", settings)
    
    # å…ˆå–å¾—èˆŠçš„è¨­å®šå€¼ç”¨æ–¼æ¯”è¼ƒ
    previous_settings = cl.user_session.get('current_settings', {})
    
    # å„²å­˜ç•¶å‰è¨­å®šåˆ° session ä¸­
    cl.user_session.set('current_settings', settings)
    
    mcp_manager = cl.user_session.get('mcp_manager')
    if not mcp_manager:
        return
    
    chat_setting = cl.user_session.get('chat_setting')
    for element in chat_setting:
        element.initial = settings.get(element.id, False)

    # è™•ç†è¦–è¦ºèªè¨€æ¨¡å‹è¨­å®šè®Šæ›´
    use_vision_model = settings.get("use_vision_model", False)
    previous_use_vision_model = previous_settings.get("use_vision_model", False)
    
    # åªæœ‰åœ¨è¨­å®šçœŸæ­£æ”¹è®Šæ™‚æ‰ç™¼é€é€šçŸ¥
    if use_vision_model != previous_use_vision_model:
        if use_vision_model:
            await cl.Message(content="å·²å•Ÿç”¨è¦–è¦ºèªè¨€æ¨¡å‹ä¾†æè¿°æª”æ¡ˆä¸­çš„åœ–ç‰‡").send()
        else:
            await cl.Message(content="å·²åœç”¨æª”æ¡ˆè§£æçš„åœ–ç‰‡æè¿°åŠŸèƒ½").send()

    # è™•ç†æ¯å€‹ MCP ä¼ºæœå™¨çš„è¨­å®šè®Šæ›´
    mcp_config = get_mcp_servers_config(cl.user_session.get('file_folder'))
    for server_name, config in mcp_config.items():
        setting_key = f"mcp_{server_name}"
        is_enabled = settings.get(setting_key, False)
        is_connected = mcp_manager.is_connected(server_name)
        
        if is_enabled and not is_connected:
            # éœ€è¦é€£ç·šä½†å°šæœªé€£ç·š
            await mcp_manager.add_connection(server_name, config)
            await cl.Message(content=f"â³ æ­£åœ¨é€£ç·šåˆ° MCP ä¼ºæœå™¨: {server_name}").send()
            
        elif not is_enabled and is_connected:
            # éœ€è¦æ–·ç·šä½†ä»åœ¨é€£ç·šä¸­
            await mcp_manager.remove_connection(server_name)
            await cl.Message(content=f"ğŸ”Œ å·²æ–·ç·š MCP ä¼ºæœå™¨: {server_name}").send()
    
    # æ›´æ–°å·¥å…·åˆ—è¡¨
    await mcp_manager.update_tools()

@cl.step(type="tool", name="MCPå·¥å…·", show_input=True)
async def execute_tool(tool_name: str, tool_input: Dict[str, Any]):
    # å‹•æ…‹è¨­å®šæ­¥é©Ÿåç¨±
    if cl.context.current_step:
        cl.context.current_step.name = f"MCPå·¥å…·: {tool_name}"
    
    mcp_manager = cl.user_session.get('mcp_manager')
    print("Executing tool:", tool_name)
    print("Tool input:", tool_input)
    mcp_name = None
    mcp_tools = mcp_manager.tools

    # æ‰¾åˆ°åŒ…å«æ­¤å·¥å…·çš„ MCP ä¼ºæœå™¨
    for conn_name, tools in mcp_tools.items():
        if any(tool["name"] == tool_name for tool in tools):
            mcp_name = conn_name
            break

    if not mcp_name:
        return {"error": f"Tool '{tool_name}' not found in any connected MCP server"}

    try:
        result = await mcp_manager.call_tool(mcp_name, tool_name, tool_input)
        return result
    except Exception as e:
        return {"error": f"Error calling tool '{tool_name}': {str(e)}"}


async def format_tools_for_openai(tools: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    openai_tools = []

    for tool in tools:
        openai_tool = {
            "type": "function",
            "function": {
                "name": tool["name"],
                "description": tool["description"],
                "parameters": tool["input_schema"],
            },
        }
        openai_tools.append(openai_tool)

    return openai_tools


def format_calltoolresult_content(result):
    """Extract text content from a CallToolResult object.

    The MCP CallToolResult contains a list of content items,
    where we want to extract text from TextContent type items.
    """
    text_contents = []

    if isinstance(result, CallToolResult):
        for content_item in result.content:
            # This script only supports TextContent but you can implement other CallToolResult types
            if isinstance(content_item, TextContent):
                text_contents.append(content_item.text)

    if text_contents:
        return "\n".join(text_contents)
    return str(result)

async def process_llm_response(message_history, initial_msg=None):
    """
    è™•ç† LLM å›ç­”èˆ‡éè¿´å·¥å…·å‘¼å«ï¼Œç›´åˆ°æ²’æœ‰ tool call ç‚ºæ­¢ã€‚
    """
    llm_client = get_llm_client(mode="async")
    mcp_tools = cl.user_session.get("mcp_manager").tools
    all_tools = []
    for connection_tools in mcp_tools.values():
        all_tools.extend(connection_tools)

    chat_params = get_model_setting()
    if all_tools:
        openai_tools = await format_tools_for_openai(all_tools)
        chat_params["tools"] = openai_tools
        chat_params["tool_choice"] = "auto"

    # ç”¨æ–¼ streaming å›è¦†
    msg_obj = initial_msg or cl.Message(content="")

    while True:
        stream = await llm_client.chat.completions.create(
            messages=message_history, **chat_params
        )

        response_text = ""
        tool_calls = []

        async for chunk in stream:
            if not chunk.choices:
                continue
            delta = chunk.choices[0].delta

            if token := delta.content or "":
                response_text += token
                await msg_obj.stream_token(token)

            if delta.tool_calls:
                for tool_call in delta.tool_calls:
                    tc_id = tool_call.index
                    if tc_id >= len(tool_calls):
                        tool_calls.append({"name": "", "arguments": ""})

                    if tool_call.function.name:
                        tool_calls[tc_id]["name"] = tool_call.function.name

                    if tool_call.function.arguments:
                        tool_calls[tc_id]["arguments"] += tool_call.function.arguments

        # å¦‚æœæœ‰ assistant å›è¦†å…§å®¹ï¼ŒåŠ å…¥æ­·å²
        if response_text.strip():
            message_history.append({"role": "assistant", "content": response_text})
            cl.user_session.set("message_history", message_history)

        # å¦‚æœæœ‰ tool callï¼ŒåŸ·è¡Œå·¥å…·ä¸¦å°‡çµæœåŠ å…¥æ­·å²ï¼Œç„¶å¾Œ loop å†ä¸Ÿçµ¦ LLM
        if tool_calls:
            # ç”Ÿæˆä¸€è‡´çš„ tool_call_id åŸºç¤å€¼
            base_call_id = len(message_history)
            
            # å…ˆå°‡ assistant çš„ tool_calls è¨Šæ¯åŠ å…¥æ­·å²
            tool_calls_formatted = []
            for i, tool_call in enumerate(tool_calls):
                tool_call_id = f"call_{base_call_id}_{i}"
                tool_calls_formatted.append({
                    "id": tool_call_id,
                    "type": "function",
                    "function": {
                        "name": tool_call["name"],
                        "arguments": tool_call["arguments"],
                    },
                })
            
            # å…ˆåŠ å…¥ assistant è¨Šæ¯ï¼ˆåŒ…å«æ‰€æœ‰ tool_callsï¼‰
            message_history.append({
                "role": "assistant",
                "content": None,
                "tool_calls": tool_calls_formatted,
            })
            cl.user_session.set("message_history", message_history)
            # åŸ·è¡Œæ¯å€‹å·¥å…·ä¸¦åŠ å…¥å°æ‡‰çš„ tool å›æ‡‰
            for i, tool_call in enumerate(tool_calls):
                tool_name = tool_call["name"]
                tool_call_id = f"call_{base_call_id}_{i}"
                
                # è¨˜éŒ„å·¥å…·åŸ·è¡Œå‰çš„æª”æ¡ˆç‹€æ…‹ï¼ˆåŒ…å«ä¿®æ”¹æ™‚é–“ï¼‰
                file_folder = cl.user_session.get('file_folder')
                existing_files = await get_files_state(file_folder)
                
                tool_result_content = None
                
                try:
                    tool_args = json.loads(tool_call["arguments"])

                    # Execute the tool in a step
                    tool_result = await execute_tool(tool_name, tool_args)
                    
                    # Format the tool result content
                    tool_result_content = format_calltoolresult_content(tool_result)

                    
                except asyncio.CancelledError:
                    # ç”¨æˆ¶ä¸»å‹•ä¸­æ–·ï¼ŒåŠ å…¥ä¸­æ–·è¨Šæ¯åˆ°æ­·å²ä¸­
                    tool_result_content = f"Tool {tool_name} was cancelled by user"

                except Exception as e:
                    error_msg = f"Error executing tool {tool_name}: {str(e)}"
                    error_message = cl.Message(content=error_msg)
                    await error_message.send()
                    
                    # è¨­å®šéŒ¯èª¤è¨Šæ¯ä½œç‚ºå·¥å…·å›æ‡‰å…§å®¹
                    tool_result_content = error_msg

                # ç¢ºä¿æ¯å€‹ tool_call_id åªå°æ‡‰ä¸€å€‹ tool å›æ‡‰è¨Šæ¯
                if tool_result_content is not None:
                    message_history.append({
                        "role": "tool",
                        "tool_call_id": tool_call_id,
                        "content": tool_result_content,
                    })
                    cl.user_session.set("message_history", message_history)
                    
                # æª¢æŸ¥æ˜¯å¦æœ‰æ–°çš„æª”æ¡ˆç”¢ç”Ÿ
                await check_and_process_new_files(existing_files)
                    
            # æœ‰ tool callï¼Œç¹¼çºŒ while loopï¼ˆå†ä¸Ÿçµ¦ LLMï¼‰
            # ä¸¦ç”¨æ–°çš„ cl.Message ç‰©ä»¶åš streaming
            msg_obj = cl.Message(content="")
        
            continue
        else:

            break

    # æ›´æ–° session message history
    cl.user_session.set("message_history", message_history)

@cl.step(type="tool", name="åæ€", show_input=False)
async def overse(message_history):
    # ====== åœ¨é€™è£¡å•Ÿå‹• Overseer ======
    goal = cl.user_session.get("task_goal") or "ï¼ˆæœªæä¾›æ˜ç¢ºä»»å‹™ç›®æ¨™ï¼Œå»ºè­°åœ¨å…¥å ´æ™‚å°±ä¿å­˜ï¼‰"
    overseer_report = await run_overseer(goal, message_history)

    # æŠŠ overseer çš„çµæœå­˜èµ·ä¾†ï¼Œä¸‹ä¸€è¼ªå¯ä¾›ä¸» Agent åƒè€ƒ
    cl.user_session.set("overseer_report", overseer_report)
    # ä¹Ÿå¯ä»¥æŠŠå®ƒ append å› message_historyï¼Œä½œç‚ºä¸‹ä¸€è¼ªæç¤º
    message_history.append({
        "role": "assistant",
        "name": "overseer",
        "content": json.dumps(overseer_report, ensure_ascii=False)
    })
    cl.user_session.set("message_history", message_history)

    # è¦–éœ€æ±‚æŠŠçµæœå›é¥‹çµ¦ä½¿ç”¨è€…ï¼ˆå¯ç”¨æ›´äººæ€§åŒ–æ¸²æŸ“ï¼‰
    # human_friendly = render_overseer_for_user(overseer_report)
    # await cl.Message(content=human_friendly).send()

    # ä½ å¯ä»¥ä¾æ“š overseer çš„ status åšå¾ŒçºŒæ§åˆ¶ï¼š
    status = overseer_report.get("status")
    if status == "continue":
        # å°‡ overseer å»ºè­°çš„ next_actionsï¼ˆå¦‚æœæœ‰ï¼‰è½‰æˆä¸‹ä¸€è¼ªæç¤ºï¼Œæˆ–ç›´æ¥è®“ä¸» Agent æ¥æ‰‹
        # é€™é‚Šä½ å¯ä»¥æŠŠ next_actions ä½œç‚ºã€Œsystem or user messageã€æç¤ºçµ¦ä¸» Agent
        pass
    elif status == "need_user_input":
        # å¼•å°ä½¿ç”¨è€…æä¾› overseer_report["ask_user"] çš„è³‡è¨Š
        pass
    else:  # "terminate"
        # æ˜ç¢ºå°ä½¿ç”¨è€…èªªæ˜çµ‚æ­¢åŸå›  & å»ºè­°
        pass
    return overseer_report
    
@cl.on_message
async def on_message(message: cl.Message):
    new_message =  {
        "role": "user",
        "content": [
            {
                "type": "text",
                "text":  message.content
            }
        ]
    }
    images = [file for file in message.elements if "image" in file.mime]
    # æ”¯æ´çš„æ–‡ä»¶å‰¯æª”å
    supported_docs = ['.pdf', '.ppt', '.pptx', '.xls', '.xlsx', '.doc', '.docx']
    # å–å¾—è¦–è¦ºèªè¨€æ¨¡å‹è¨­å®š
    current_settings = cl.user_session.get('current_settings', {})
    use_vision_model = current_settings.get("use_vision_model", False)
    # å·²è™•ç†çš„æª”æ¡ˆé›†åˆ
    handled_files = set()
    # æ–‡ä»¶è™•ç†
    for file in message.elements:
        ext = os.path.splitext(file.name)[1].lower()
        if ext in supported_docs:
            content = await convert_to_markdown(file.path, use_vision_model=use_vision_model)
            new_message['content'].append(
                {
                    "type": "text",
                    "text": content
                }
            )
            handled_files.add(file.name)
    # åœ–ç‰‡è™•ç†
    for image in images:
        new_message['content'].append(
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{await encode_image(image.path)}",
                    "detail": "high"
                }
            }
        )
        handled_files.add(image.name)
    # å…¶ä»–æœªè™•ç†æ ¼å¼è¨»è¨˜
    for file in message.elements:
        if file.name not in handled_files:
            ext = os.path.splitext(file.name)[1].lower()
            # è¨»è¨˜æ”¶åˆ°çš„éæ”¯æ´æ ¼å¼
            new_message['content'].append(
                {
                    "type": "text",
                    "text": f"ï¼ˆå·²æ”¶åˆ°æª”æ¡ˆï¼š{os.path.basename(file.path)}ï¼‰"
                }
            )
    message_history = cl.user_session.get("message_history", [])
    message_history.append(new_message)
    try:
        await process_llm_response(message_history)
    except Exception as e:
        error_message = f"Error: {str(e)}"
        await cl.Message(content=error_message).send()

async def on_mcp_progress(mcp_name: str, message: str, progress: int, total: int):
    mcp_manager = cl.user_session.get('mcp_manager')
    try:
        # è™•ç†æœ¬å°ˆæ¡ˆè‡ªå®šç¾©è¨Šæ¯æ ¼å¼é¡¯ç¤ºåœ¨å´é‚Šæ¬„
        if mcp_manager['mcp_name'].get('use_artifact'):
            """è™•ç† MCP é€²åº¦é€šçŸ¥ä¸¦æ›´æ–° ElementSidebar"""
            # è§£æ JSON è¨Šæ¯
            notification_data = json.loads(message)
            
            # æº–å‚™ ElementSidebar çš„å…ƒç´ 
            elements = []
            
            # è™•ç†æ¯å€‹å…ƒç´ 
            for element in notification_data.get("elements", []):
                if element["type"] == "text":
                    # å‰µå»ºæ–‡å­—å…ƒç´ 
                    text_element = cl.Text(
                        name=f"text_{len(elements)}",
                        content=element["content"]
                    )
                    elements.append(text_element)
                    
                elif element["type"] == "image":
                    # å‰µå»ºåœ–ç‰‡å…ƒç´ 
                    # ç›´æ¥ä½¿ç”¨ base64 æ•¸æ“šå‰µå»º data URLï¼Œä¸ä¿å­˜åˆ°æª”æ¡ˆ
                    
                    # å‰µå»ºåœ–ç‰‡å…ƒç´ ï¼Œä½¿ç”¨ data URL
                    data_url = f"data:image/png;base64,{element['content']}"
                    image_element = cl.Image(
                        name=f"screenshot_{len(elements)}",
                        url=data_url,
                        display="side"
                    )
                    elements.append(image_element)
            
            # ä½¿ç”¨å”¯ä¸€çš„ key æ›´æ–° ElementSidebar
            import time
            unique_key = f"browser_progress_{int(time.time() * 1000)}"
            
            if elements:
                await cl.ElementSidebar.set_elements(elements, key=unique_key)
        else:
            await cl.Message(content=message).send()

    except Exception as e:
        print(f"è™•ç†é€²åº¦é€šçŸ¥æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")

async def on_mcp_elicit(elicte_param) -> Literal["accept", "decline", "cancel"]:
    res = await cl.AskActionMessage(
        content=elicte_param.get('message'),
        actions=[
            cl.Action(name="accept", payload={"value": "accept"}, label="âœ”ï¸ æ¥å—"),
            cl.Action(name="decline", payload={"value": "decline"}, label="âŒ æ‹’çµ•"),
        ],
    ).send()

    return res.get("payload").get("value")
        
if __name__ == '__main__':
    from chainlit.cli import run_chainlit
    run_chainlit(__file__)
